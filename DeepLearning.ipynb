{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNN6ymUpd01YVMnTPBbJhJJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranamahmoud12/AssignmentDL/blob/main/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i6Q4hdkwAgAi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import itertools\n",
        "from sklearn.utils import shuffle\n",
        "from keras.metrics import AUC, Recall, Precision, SpecificityAtSensitivity, SensitivityAtSpecificity, FalseNegatives, FalsePositives, TrueNegatives, TruePositives,F1Score\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "# from keras.applications.vgg19 import VGG19\n",
        "\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "import os\n",
        "from keras.regularizers import l2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob as gb\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rx7siS9BHrc",
        "outputId": "6a37a46a-fe59-4d02-bdc9-203a7645bc40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_width=224\n",
        "img_height=224\n",
        "img_size=128\n",
        "epochs=50\n",
        "NUM_CLASSES=2"
      ],
      "metadata": {
        "id": "Vqu7n8mKBLZQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    rotation_range=180,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    '/content/drive/MyDrive/DeepLearning/Train',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    class_mode='binary',  # Change this to 'binary'\n",
        "    seed=42,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    '/content/drive/MyDrive/DeepLearning/Test',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    class_mode='binary',  # Change this to 'binary'\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4BDvKaRBM97",
        "outputId": "40d9229d-dfa1-43ed-8b0e-5971e9adcb43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 84 images belonging to 2 classes.\n",
            "Found 4 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size = []\n",
        "\n",
        "# Loop through folders in the training directory\n",
        "for folder in os.listdir('/content/drive/MyDrive/DeepLearning/Train'):\n",
        "    folder_path = os.path.join('/content/drive/MyDrive/DeepLearning/Train', folder)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Use glob to get all JPEG files in the folder\n",
        "        files = gb.glob(os.path.join(folder_path, '*.jpg'))\n",
        "\n",
        "        # Loop through each file\n",
        "        for file in files:\n",
        "            # Read the image\n",
        "            image = plt.imread(file)\n",
        "            # Get the size and append to the list\n",
        "            size.append(image.shape)\n",
        "\n",
        "# Create a Pandas Series and print the value counts\n",
        "size_series = pd.Series(size)\n",
        "print(size_series.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUR62aVGBO8y",
        "outputId": "6baafc26-d4fa-4ee4-b408-68f7999cd138"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3)    104\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size = []\n",
        "\n",
        "# Loop through folders in the test directory\n",
        "for folder in os.listdir('/content/drive/MyDrive/DeepLearning/Test'):\n",
        "    folder_path = os.path.join('/content/drive/MyDrive/DeepLearning/Test', folder)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Use glob to get all JPEG files in the folder\n",
        "        files = gb.glob(os.path.join(folder_path, '*.jpg'))\n",
        "\n",
        "        # Loop through each file\n",
        "        for file in files:\n",
        "            # Read the image\n",
        "            image = plt.imread(file)\n",
        "            # Get the size and append to the list\n",
        "            size.append(image.shape)\n",
        "\n",
        "# Create a Pandas Series and print the value counts\n",
        "size_series = pd.Series(size)\n",
        "print(size_series.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G849Mw2QBQ25",
        "outputId": "6e2ecadd-71e1-416a-b239-ff3e73795297"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3)    24\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping dictionary for class labels\n",
        "class_mapping = {'Class (1)': 0, 'Class (2)': 1}  # Add more classes as needed\n",
        "img_size=256"
      ],
      "metadata": {
        "id": "_K3cIvVdBS36"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(file_paths, img_size):\n",
        "    images = []\n",
        "    for file_path in file_paths:\n",
        "        # Read and preprocess the image\n",
        "        img = cv2.imread(file_path)\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        img = img / 255.0  # Normalize the pixel values to the range [0, 1]\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Now, your code to load and preprocess training images\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "# Loop through folders in the training directory\n",
        "for folder in os.listdir('/content/drive/MyDrive/DeepLearning/Train'):\n",
        "    folder_path = os.path.join('/content/drive/MyDrive/DeepLearning/Train', folder)\n",
        "\n",
        "    if os.path.isdir(folder_path):\n",
        "        files = gb.glob(os.path.join(folder_path, '*.jpg'))\n",
        "        x_train.extend(files)\n",
        "        y_train.extend([folder] * len(files))\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Load and preprocess training images\n",
        "x_train = load_images(x_train, img_size)\n",
        "y_train = np.array([class_mapping[label] for label in y_train])\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur6IoHKABTkJ",
        "outputId": "68644fa8-5b1a-4581-c5d6-42a80b4b82eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(104, 256, 256, 3)\n",
            "(104,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "# Loop through folders in the test directory\n",
        "for folder in os.listdir('/content/drive/MyDrive/DeepLearning/Test'):\n",
        "    folder_path = os.path.join('/content/drive/MyDrive/DeepLearning/Test', folder)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Use glob to get all JPEG files in the folder\n",
        "        files = gb.glob(os.path.join(folder_path, '*.jpg'))\n",
        "\n",
        "        # Append file paths and corresponding labels\n",
        "        x_test.extend(files)\n",
        "        y_test.extend([folder] * len(files))\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Load and preprocess test images\n",
        "x_test = load_images(x_test, img_size)\n",
        "y_test = to_categorical(np.array([class_mapping[label] for label in y_test]))\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKyIzIB3BWTF",
        "outputId": "faa2101d-7ab6-4e8d-a688-178257931807"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24, 256, 256, 3)\n",
            "(24, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train/255\n",
        "x_test=x_test/255"
      ],
      "metadata": {
        "id": "2KxBeblpBYha"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
        "\n",
        "print(x_valid.shape)\n",
        "print(y_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8GNq7LIBbHs",
        "outputId": "92b9b1b0-11f2-447d-cd1c-8384538900fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 256, 256, 3)\n",
            "(32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_shape = (img_size, img_size, 3)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add the pre-trained AlexNet model\n",
        "model.add(base_model)\n",
        "\n",
        "# Flatten the output of the AlexNet model\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add some dense layers with dropout for classification\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_z4jiclBcoq",
        "outputId": "ed30eb51-c0f6-4e71-aea1-7a54a63b98ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 131072)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              536875008 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 577248129 (2.15 GB)\n",
            "Trainable params: 577195009 (2.15 GB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = np.array([10, 20, 30])\n",
        "total_samples = np.sum(class_counts)\n",
        "class_weights = total_samples / (len(class_counts) * np.array(class_counts, dtype=float))\n",
        "\n",
        "class_weights_list = class_weights.tolist()\n",
        "class_weight_dict = {i: class_weights_list[i] for i in range(len(class_weights_list))}\n",
        "\n",
        "print(class_weight_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwMs-UsQBehy",
        "outputId": "43b78ef3-f4ff-4bd5-cf37-b6290a2d3099"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 2.0, 1: 1.0, 2: 0.6666666666666666}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile the model with the specified class weights\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        AUC(),\n",
        "        Recall(),\n",
        "        Precision(),\n",
        "        SpecificityAtSensitivity(0.5),\n",
        "        SensitivityAtSpecificity(0.5),\n",
        "        FalseNegatives(),\n",
        "        FalsePositives(),\n",
        "        TrueNegatives(),\n",
        "        TruePositives()\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train the model with class weights\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=50, validation_data=(x_valid, y_valid), callbacks=[early_stopping], class_weight=class_weight_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77kCac1LBgG8",
        "outputId": "d8a1ee2b-ab98-4ce9-fb86-34344cc5bd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure test data is in the correct format\n",
        "x_test = x_test.astype(np.float32)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "evaluation_results = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Loss: {evaluation_results[0]}\")\n",
        "print(f\"Test Accuracy: {evaluation_results[1]}\")\n"
      ],
      "metadata": {
        "id": "0EWrtp0VBiM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"Val loss for \"+dataset+\" \"+impl_type+\"\\n\"\n",
        "\n",
        "plt.plot(log_data['loss'])\n",
        "plt.plot(log_data['val_loss'])\n",
        "plt.title(title)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss','val_loss'], loc = 'best')\n",
        "plt.grid(b=True, which='major', axis='both')\n",
        "\n",
        "img_path = work_dir+'vLoss_'+checkpointer_name[8:-5]+'.png'\n",
        "plt.savefig(img_path, dpi=600)\n",
        "plt.show()\n",
        "print('img_path =', img_path)"
      ],
      "metadata": {
        "id": "zcGgPwaFEoOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"Val acc for \"+dataset+\" \"+impl_type+\"\\n\"\n",
        "\n",
        "plt.plot(log_data['accuracy'])\n",
        "plt.plot(log_data['val_accuracy'])\n",
        "plt.title(title)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_accuracy','val_accuracy'], loc = 'best')\n",
        "plt.grid(b=True, which='major', axis='both')\n",
        "\n",
        "img_path = work_dir+'vAcc_'+checkpointer_name[8:-5]+'.png'\n",
        "plt.savefig(img_path, dpi=600)\n",
        "plt.show()\n",
        "print('img_path =', img_path)"
      ],
      "metadata": {
        "id": "AZXAoLamEpg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6DL8Ha3jEx94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}